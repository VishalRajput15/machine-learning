{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "H1SV9FuOnlTS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_NAADFQogQW",
        "outputId": "60b17ff6-9c0c-44e2-cf04-d9647dcaba6f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/reviews_data.csv')"
      ],
      "metadata": {
        "id": "SHffXwSpole1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Data Sample:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7ZotKr9o92-",
        "outputId": "9f76d53b-17fb-43fe-eba7-423af0495ce4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data Sample:\n",
            "       name           location                     Date  Rating  \\\n",
            "0     Helen  Wichita Falls, TX  Reviewed Sept. 13, 2023     5.0   \n",
            "1  Courtney         Apopka, FL   Reviewed July 16, 2023     5.0   \n",
            "2  Daynelle  Cranberry Twp, PA    Reviewed July 5, 2023     5.0   \n",
            "3    Taylor        Seattle, WA    Reviewed May 26, 2023     5.0   \n",
            "4   Tenessa        Gresham, OR   Reviewed Jan. 22, 2023     5.0   \n",
            "\n",
            "                                              Review  \\\n",
            "0  Amber and LaDonna at the Starbucks on Southwes...   \n",
            "1  ** at the Starbucks by the fire station on 436...   \n",
            "2  I just wanted to go out of my way to recognize...   \n",
            "3  Me and my friend were at Starbucks and my card...   \n",
            "4  I’m on this kick of drinking 5 cups of warm wa...   \n",
            "\n",
            "                                         Image_Links  \n",
            "0                                      ['No Images']  \n",
            "1                                      ['No Images']  \n",
            "2  ['https://media.consumeraffairs.com/files/cach...  \n",
            "3                                      ['No Images']  \n",
            "4  ['https://media.consumeraffairs.com/files/cach...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2cHevnaphit",
        "outputId": "8ebdac9f-f414-4da9-e8f8-f06834de5c5d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(850, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trueZg0dpi91",
        "outputId": "df073336-0aa6-43ed-f232-98c7a6fdeaa8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 850 entries, 0 to 849\n",
            "Data columns (total 6 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   name         850 non-null    object \n",
            " 1   location     850 non-null    object \n",
            " 2   Date         850 non-null    object \n",
            " 3   Rating       705 non-null    float64\n",
            " 4   Review       850 non-null    object \n",
            " 5   Image_Links  850 non-null    object \n",
            "dtypes: float64(1), object(5)\n",
            "memory usage: 40.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lowercase(text):\n",
        "    return text.lower()"
      ],
      "metadata": {
        "id": "Mr9G9dF9o8Ql"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_urls(text):\n",
        "    return re.sub(r'https?://\\S+|www\\.\\S+', '', text)"
      ],
      "metadata": {
        "id": "6dNfq2OZo5Uc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_html(text):\n",
        "    return re.sub(r'<.*?>', '', text)"
      ],
      "metadata": {
        "id": "XaTyjU8jo4Gk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_special(text):\n",
        "    return re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)"
      ],
      "metadata": {
        "id": "y_Y-g7Hno24V"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_numbers(text):\n",
        "    return re.sub(r'\\d+', '', text)"
      ],
      "metadata": {
        "id": "jTjaV_Ylo1Qd"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    return text.split()"
      ],
      "metadata": {
        "id": "tANEcLRvo0Hk"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "def remove_stopwords(tokens):\n",
        "    return [word for word in tokens if word not in stop_words]"
      ],
      "metadata": {
        "id": "9c3_9rBBoypN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize(tokens):\n",
        "    return [lemmatizer.lemmatize(word) for word in tokens]"
      ],
      "metadata": {
        "id": "4Td0npgBoxL1"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = lowercase(str(text))\n",
        "    text = remove_urls(text)\n",
        "    text = remove_html(text)\n",
        "    text = remove_special(text)\n",
        "    text = remove_numbers(text)\n",
        "    tokens = tokenize(text)\n",
        "    tokens = remove_stopwords(tokens)\n",
        "    tokens = lemmatize(tokens)\n",
        "    return ' '.join(tokens)\n"
      ],
      "metadata": {
        "id": "HvBRcmEios0V"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cleaned_review'] = df['Review'].apply(clean_text)"
      ],
      "metadata": {
        "id": "2L0bNe3NorRU"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCleaned Reviews Sample:\")\n",
        "print(df[['Review','cleaned_review']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlsUPa7eoqEN",
        "outputId": "cfcf2bfd-d586-4740-cfe1-8dc15c6456ff"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaned Reviews Sample:\n",
            "                                              Review  \\\n",
            "0  Amber and LaDonna at the Starbucks on Southwes...   \n",
            "1  ** at the Starbucks by the fire station on 436...   \n",
            "2  I just wanted to go out of my way to recognize...   \n",
            "3  Me and my friend were at Starbucks and my card...   \n",
            "4  I’m on this kick of drinking 5 cups of warm wa...   \n",
            "\n",
            "                                      cleaned_review  \n",
            "0  amber ladonna starbucks southwest parkway alwa...  \n",
            "1  starbucks fire station altamonte spring fl mad...  \n",
            "2  wanted go way recognize starbucks employee bil...  \n",
            "3  friend starbucks card work thankful worker pai...  \n",
            "4  kick drinking cup warm water work instacart ri...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('starbucks_reviews_cleaned.csv', index=False)\n",
        "print(\"\\nSaved cleaned file.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h016qI7noo9N",
        "outputId": "aa49c2e0-80d2-4f93-d6f2-b83f642783d5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved cleaned file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dGLyjnKkp3ql"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}